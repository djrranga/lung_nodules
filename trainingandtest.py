# -*- coding: utf-8 -*-
"""
LUNA16 Multi-view ResNet50 Training + Testing
Using only preprocessed views9/ generated by preprocess3d.py
"""

import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchvision
from tqdm import tqdm
from glob import glob
from collections import defaultdict


######################################################################
# 1. BUILD UID → SUBSET MAP (based on original LUNA directory)
######################################################################

def build_uid_subset_map(base_dir="."):
    """
    This looks for folder subset0/... subset9/, finds all MHD files,
    and maps UID → subset number. Required to replicate LUNA16 split.
    """
    uid_to_subset = {}
    for s in range(10):
        subset_path = os.path.join(base_dir, f"subset{s}")
        if not os.path.isdir(subset_path):
            continue

        mhd_files = glob(os.path.join(subset_path, "*.mhd"))
        for m in mhd_files:
            uid = os.path.splitext(os.path.basename(m))[0]
            uid_to_subset[uid] = s

    print("Total UIDs mapped:", len(uid_to_subset))
    return uid_to_subset


uid_subset_map = build_uid_subset_map(".")  # Must match your LongLeaf directory structure


######################################################################
# 2. DATASET: loads 9 views from views9/ and matches LUNA16 subsets
######################################################################

class LunaMultiViewDataset(Dataset):
    """
    Loads preprocessed 9-view .npy files:
        shape = (9,48,48)

    Returns:
        - views: (9,1,48,48)
        - label: 0/1 from candidates_V2.csv
    """
    def __init__(self, views_dir="views9", candidates_csv="candidates_V2.csv", subset_ids=None):
        self.views_dir = views_dir
        self.df = pd.read_csv(candidates_csv)
        self.files = sorted(os.listdir(views_dir))
        self.subset_ids = subset_ids
        self.filtered_files = []

        for f in self.files:
            # Filename pattern: UID_rowIndex.npy
            uid = f.split("_")[0]
            subset = uid_subset_map.get(uid, None)

            if subset in subset_ids:
                self.filtered_files.append(f)

        print(f"Loaded {len(self.filtered_files)} samples from subsets {subset_ids}")

    def __len__(self):
        return len(self.filtered_files)

    def __getitem__(self, idx):
        fname = self.filtered_files[idx]
        path = os.path.join(self.views_dir, fname)

        views = np.load(path)  # (9,48,48)
        views = torch.tensor(views, dtype=torch.float32).unsqueeze(1)  # (9,1,48,48)

        row_idx = int(fname.split("_")[-1].split(".")[0])
        label = int(self.df.iloc[row_idx]["class"])

        return views, torch.tensor(label, dtype=torch.long)


######################################################################
# 3. Multi-view ResNet50 (Hendrikx style architecture)
######################################################################

class MultiViewResNet50(nn.Module):
    def __init__(self, num_views=9, num_classes=2):
        super().__init__()

        base = torchvision.models.resnet50(weights="IMAGENET1K_V2")

        # Modify first conv layer to accept grayscale
        base.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)

        # Use everything except final FC layer
        self.backbone = nn.Sequential(*list(base.children())[:-1])
        self.feat_dim = base.fc.in_features

        self.classifier = nn.Sequential(
            nn.Linear(self.feat_dim * num_views, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes),
        )

    def forward(self, views):
        # views: (B,9,1,48,48)
        B, V, C, H, W = views.shape
        feats = []

        for v in range(V):
            f = self.backbone(views[:, v])  # (B,2048,1,1)
            feats.append(f.view(B, -1))

        feats = torch.cat(feats, dim=1)  # (B, 9*2048)
        return self.classifier(feats)


######################################################################
# 4. Load datasets (LUNA split A)
######################################################################

train_ds = LunaMultiViewDataset(
    views_dir="views9",
    candidates_csv="candidates_V2.csv",
    subset_ids=list(range(1, 9))
)

val_ds = LunaMultiViewDataset(
    views_dir="views9",
    candidates_csv="candidates_V2.csv",
    subset_ids=[9]
)

test_ds = LunaMultiViewDataset(
    views_dir="views9",
    candidates_csv="candidates_V2.csv",
    subset_ids=[0]
)

train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=4)
val_loader   = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=4)
test_loader  = DataLoader(test_ds, batch_size=16, shuffle=False, num_workers=4)


######################################################################
# 5. Training utilities
######################################################################

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Training on:", device)

model = MultiViewResNet50(num_views=9, num_classes=2).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)


def train_one_epoch():
    model.train()
    total_loss = 0

    for views, labels in tqdm(train_loader, desc="Training"):
        views, labels = views.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(views)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    return total_loss / len(train_loader)


def evaluate(loader):
    model.eval()
    correct = 0
    total = 0

    with torch.no_grad():
        for views, labels in loader:
            views, labels = views.to(device), labels.to(device)
            preds = model(views).argmax(dim=1)

            correct += (preds == labels).sum().item()
            total += labels.size(0)

    return correct / total


######################################################################
# 6. Main training loop
######################################################################

EPOCHS = 10

for epoch in range(EPOCHS):
    train_loss = train_one_epoch()
    val_acc = evaluate(val_loader)
    print(f"[Epoch {epoch+1}/{EPOCHS}]  Loss={train_loss:.4f}  Val Acc={val_acc:.4f}")

torch.save(model.state_dict(), "multiview_resnet50.pth")
print("Model saved as multiview_resnet50.pth")


######################################################################
# 7. Final Testing (subset0)
######################################################################

test_acc = evaluate(test_loader)
print("Final Test Accuracy:", test_acc)